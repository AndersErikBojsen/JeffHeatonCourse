{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the origional column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df,name,target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x)==str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name,tv)\n",
    "        df[name2] = l\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    \n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.int32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "# Regression chart, we will see more of this chart in the next class.\n",
    "def chart_regression(pred,y):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y})\n",
    "    t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# Get a new directory to hold checkpoints from a neural network.  This allows the neural network to be\n",
    "# loaded later.  If the erase param is set to true, the contents of the directory will be cleared.\n",
    "def get_model_dir(name,erase):\n",
    "    base_path = os.path.join(\".\",\"dnn\")\n",
    "    model_dir = os.path.join(base_path,name)\n",
    "    os.makedirs(model_dir,exist_ok=True)\n",
    "    if erase and len(model_dir)>4 and os.path.isdir(model_dir):\n",
    "        shutil.rmtree(model_dir,ignore_errors=True) # be careful, this deletes everything below the specified path\n",
    "    return model_dir\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name]-df[name].mean())>=(sd*df[name].std()))]\n",
    "    df.drop(drop_rows,axis=0,inplace=True)\n",
    "    \n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low =-1, normalized_high =1, \n",
    "                         data_low=None, data_high=None):\n",
    "    \n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "    \n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "                * (normalized_high - normalized_low) + normalized_low\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esses testes foram feitos com um base sobre carros e seus atributos. O objetivo é prever quantoo carro fará por litro de combustível (ou quantas milhas por galão). Abaixo segue uma porção dessa base.\n",
      "\n",
      "\n",
      "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
      "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
      "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
      "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
      "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
      "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
      "\n",
      "   origin                       name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"auto-mpg.csv\",na_values=['NA','?'])\n",
    "\n",
    "\n",
    "print(\"Esses testes foram feitos com um base sobre carros e seus atributos. O objetivo é prever quanto\"+\n",
    "      \"o carro fará por litro de combustível (ou quantas milhas por galão). Abaixo segue uma porção dessa base.\")        \n",
    "\n",
    "print(\"\\n\")\n",
    "print(df.head())\n",
    "\n",
    "#procura por colunas que tenham algum Nan\n",
    "df.isnull().any()\n",
    "#corrige Nan\n",
    "df['horsepower'][df['horsepower'].isnull()] = df.horsepower.mean()\n",
    "df.isnull().any()\n",
    "#remove nome\n",
    "df.drop('name',axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 1 - Linear Regression sem cross-validation\n",
      "Mean squared error: 3.73\n",
      "Mean squared error: 3.7294211619172484\n",
      "Mean squared error: [-17.93147744 -12.4248414  -16.31732339]\n",
      "Accuracy: 0.805\n",
      "\n",
      "\n",
      "\n",
      "Caso 2 - Linear Regression com 5 fold cross-validation\n",
      "Fold #1\n",
      "Fold score (RMSE): 3.381042537555894\n",
      "Accuracy: 0.832\n",
      "Fold #2\n",
      "Fold score (RMSE): 3.911961086667159\n",
      "Accuracy: 0.766\n",
      "Fold #3\n",
      "Fold score (RMSE): 2.8722021174011263\n",
      "Accuracy: 0.874\n",
      "Fold #4\n",
      "Fold score (RMSE): 3.571258390875969\n",
      "Accuracy: 0.742\n",
      "Fold #5\n",
      "Fold score (RMSE): 3.6208700468964556\n",
      "Accuracy: 0.808\n",
      "\n",
      "Final, out of sample score (RMSE): 3.4878372074444934\n",
      "Final, out of sample score (RMSE): 2.8509271566301924\n",
      "Final Accuracy: 0.839\n",
      "\n",
      "\n",
      "\n",
      " Tentativa de selecionar melhores features \n",
      "\n",
      "Original shape: (398, 7)\n",
      "Shape apos Removing features with low variance (398, 7)\n",
      "\n",
      "\n",
      "As features selecionadas com Tree-based feature selection foram: \n",
      "\n",
      "   cylinders  displacement  horsepower    weight  acceleration      year  \\\n",
      "0   0.324809      0.184751    0.051246  0.253654      0.034372  0.137759   \n",
      "\n",
      "     origin  \n",
      "0  0.013408  \n",
      "\n",
      " New shape apos Tree-based feature selection: (398, 3)\n",
      "\n",
      " Fim tentativa selecionar melhores features \n",
      "\n",
      "Treinando novamente somente com as features relevantes \n",
      "\n",
      "Mean squared error: 4.04\n",
      "Mean squared error: 4.043759879712534\n",
      "Mean squared error: [-22.34038031  -8.76605919 -19.55574119]\n",
      "Accuracy: 0.676\n"
     ]
    }
   ],
   "source": [
    "from sklearn                        import metrics, svm\n",
    "from sklearn.linear_model           import LinearRegression\n",
    "from sklearn.linear_model           import LogisticRegression\n",
    "from sklearn.tree                   import DecisionTreeClassifier\n",
    "from sklearn.neighbors              import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis  import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes            import GaussianNB\n",
    "from sklearn.svm                    import SVC\n",
    "from sklearn.svm                    import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#Caso 1 - Linear Regression sem cross-validation\n",
    "print(\"Caso 1 - Linear Regression sem cross-validation\")\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "classifier = LinearRegression()\n",
    "classifier.fit(x_train_scaled, y_train)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % np.sqrt(np.mean((classifier.predict(x_test_scaled) - y_test) ** 2)))\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "score=cross_val_score(classifier, x_test_scaled, y_test, scoring='neg_mean_squared_error') \n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#Caso 2 - Linear Regression com 5 fold cross-validation\n",
    "# Shuffle\n",
    "print(\"Caso 2 - Linear Regression com 5 fold cross-validation\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_train = np.asmatrix(y_train)\n",
    "y_test = np.asmatrix(y_test)\n",
    "\n",
    "classifier = LinearRegression()\n",
    "kf = KFold(5)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "\n",
    "    x_train_fold = x_train_scaled[train]\n",
    "    y_train_fold = y_train[train]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\nFinal, out of sample score (RMSE): {}\".format(score))    \n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\n Tentativa de selecionar melhores features \\n\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#Removing features with low variance\n",
    "print(\"Original shape: {}\".format(np.shape(df.iloc[:,1:])))\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "features = sel.fit_transform(df.iloc[:,1:])\n",
    "print(\"Shape apos Removing features with low variance {}\".format(np.shape(features))) #nenhuma foi selecionada \n",
    "print(\"\\n\")\n",
    "\n",
    "#Tree-based feature selection\n",
    "clf = ExtraTreesRegressor()\n",
    "clf = clf.fit(df.iloc[:,1:],df.iloc[:,0:1])\n",
    "data = np.zeros((1,df.shape[1]-1))\n",
    "data = pd.DataFrame(data, columns=df.columns[1:])\n",
    "data.iloc[0] = clf.feature_importances_\n",
    "print(\"As features selecionadas com Tree-based feature selection foram: \\n\")\n",
    "print(data)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(df.iloc[:,1:])\n",
    "print(\"\\n New shape apos Tree-based feature selection: {}\".format(X_new.shape))\n",
    "\n",
    "print(\"\\n Fim tentativa selecionar melhores features \\n\")\n",
    "\n",
    "print(\"Treinando novamente somente com as features relevantes \\n\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_new, df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "classifier = LinearRegression()\n",
    "classifier.fit(x_train_scaled, y_train)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % np.sqrt(np.mean((classifier.predict(x_test_scaled) - y_test) ** 2)))\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "score=cross_val_score(classifier, x_test_scaled, y_test, scoring='neg_mean_squared_error') \n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 2 - SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 2.268577409851733\n",
      "Accuracy: 0.879\n",
      "\n",
      "\n",
      "\n",
      "Caso 2 - SVM com cross-validation\n",
      "Fold #1\n",
      "Fold score (RMSE): 2.9698418068755643\n",
      "Accuracy: 0.845\n",
      "Fold #2\n",
      "Fold score (RMSE): 2.7273102329770085\n",
      "Accuracy: 0.881\n",
      "Fold #3\n",
      "Fold score (RMSE): 3.8080019671448335\n",
      "Accuracy: 0.782\n",
      "Fold #4\n",
      "Fold score (RMSE): 3.8054219291085762\n",
      "Accuracy: 0.772\n",
      "Fold #5\n",
      "Fold score (RMSE): 2.8166791655109833\n",
      "Accuracy: 0.869\n",
      "\n",
      "Final, out of sample score (RMSE): 3.260551172739426\n",
      "Final, out of sample score (RMSE): 3.0796532294946415\n",
      "Final Accuracy: 0.826\n"
     ]
    }
   ],
   "source": [
    "classifier = SVR()\n",
    "#Caso 3 - SVM\n",
    "# Shuffle\n",
    "print(\"Caso 2 - SVM\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.23, random_state=42) \n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "classifier.fit(x_train_scaled, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#Caso 2\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"Caso 2 - SVM com cross-validation\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_train = np.asmatrix(y_train)\n",
    "y_test = np.asmatrix(y_test)\n",
    "\n",
    "classifier = SVR()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "#x = df.as_matrix(columns=df.columns[1:])  \n",
    "#y = df.as_matrix(columns=['mpg'])\n",
    "\n",
    "\n",
    "for train, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[train]\n",
    "    y_train_fold = y_train[train]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "         \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)\n",
    "\n",
    "    # Measure accuracy\n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\nFinal, out of sample score (RMSE): {}\".format(score))    \n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "# Evaluate success using accuracy\n",
    "print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests\n",
      "Mean squared error: 3.756293718547579\n",
      "Accuracy: 0.834\n",
      "\n",
      "\n",
      "\n",
      "Random Forests com cross-validation\n",
      "Fold #1\n",
      "Fold score (RMSE): 2.80296048848356\n",
      "Accuracy: 0.900\n",
      "Fold #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (RMSE): 3.064793528934698\n",
      "Accuracy: 0.838\n",
      "Fold #3\n",
      "Fold score (RMSE): 2.764750779907657\n",
      "Accuracy: 0.844\n",
      "Fold #4\n",
      "Fold score (RMSE): 2.751170890701134\n",
      "Accuracy: 0.841\n",
      "Fold #5\n",
      "Fold score (RMSE): 2.6796265435128106\n",
      "Accuracy: 0.881\n",
      "\n",
      "Final, out of sample score (RMSE): 2.816386015566624\n",
      "Final, out of sample score (RMSE): 2.8898648324791942\n",
      "Final Accuracy: 0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "##Random Forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"Random Forests\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test,y=y_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#Caso 2\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"Random Forests com cross-validation\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "#x = df.as_matrix(columns=df.columns[1:])  \n",
    "#y = df.as_matrix(columns=['mpg'])\n",
    "\n",
    "for train, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train.as_matrix()[train]\n",
    "    y_train_fold = y_train.as_matrix()[train]\n",
    "    x_test_fold = x_train.as_matrix()[test]\n",
    "    y_test_fold = y_train.as_matrix()[test]\n",
    "    \n",
    "    #Normalization\n",
    "    #scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "    #x_train_scaled = scaler.transform(x_train)\n",
    "    #x_test_scaled = scaler.transform(x_test)\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\nFinal, out of sample score (RMSE): {}\".format(score))    \n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "# Evaluate success using accuracy\n",
    "print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test,y=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n",
      "Mean squared error: 3.184222039996583\n",
      "Accuracy: 0.841\n",
      "\n",
      "\n",
      "KNeighborsRegressor com cross-validation\n",
      "Fold #1\n",
      "Fold score (RMSE): 3.4403479111857274\n",
      "Accuracy: 0.777\n",
      "Fold #2\n",
      "Fold score (RMSE): 2.7140836390944187\n",
      "Accuracy: 0.854\n",
      "Fold #3\n",
      "Fold score (RMSE): 2.446166643955395\n",
      "Accuracy: 0.903\n",
      "Fold #4\n",
      "Fold score (RMSE): 4.041414965161945\n",
      "Accuracy: 0.750\n",
      "Fold #5\n",
      "Fold score (RMSE): 2.6845495616967754\n",
      "Accuracy: 0.873\n",
      "\n",
      "Final, out of sample score (RMSE): 3.1196841075367887\n",
      "Final, out of sample score (RMSE): 3.2500338459776077\n",
      "Final Accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "##K NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"KNeighborsRegressor\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "classifier = KNeighborsRegressor()\n",
    "\n",
    "classifier.fit(x_train_scaled, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#Caso 2\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"KNeighborsRegressor com cross-validation\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_train = np.asmatrix(y_train)\n",
    "y_test = np.asmatrix(y_test)\n",
    "\n",
    "\n",
    "classifier = KNeighborsRegressor()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "#x = df.as_matrix(columns=df.columns[1:])  \n",
    "#y = df.as_matrix(columns=['mpg'])\n",
    "\n",
    "for train, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[train]\n",
    "    y_train_fold = y_train[train]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "     \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\nFinal, out of sample score (RMSE): {}\".format(score))    \n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "# Evaluate success using accuracy\n",
    "print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN MLPRegressor\n",
      "Mean squared error: 1.974818380298283\n",
      "Accuracy: 0.941\n",
      "\n",
      "\n",
      "MLPRegressor com cross-validation\n",
      "Fold #1\n",
      "Fold score (RMSE): 2.7817672325823377\n",
      "Accuracy: 0.873\n",
      "Fold #2\n",
      "Fold score (RMSE): 3.071366709789862\n",
      "Accuracy: 0.821\n",
      "Fold #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (RMSE): 2.941369496662038\n",
      "Accuracy: 0.858\n",
      "Fold #4\n",
      "Fold score (RMSE): 2.829714765093805\n",
      "Accuracy: 0.869\n",
      "Fold #5\n",
      "Fold score (RMSE): 2.739366128815406\n",
      "Accuracy: 0.872\n",
      "\n",
      "Final, out of sample score (RMSE): 2.875783899939826\n",
      "Final, out of sample score (RMSE): 3.4824191083684615\n",
      "Final Accuracy: 0.823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"NN MLPRegressor\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.23, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15, 2), random_state=1)\n",
    "\n",
    "classifier.fit(x_train_scaled, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#Caso 2\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"MLPRegressor com cross-validation\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_train = np.asmatrix(y_train)\n",
    "y_test = np.asmatrix(y_test)\n",
    "\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15, 2), random_state=1)\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "#x = df.as_matrix(columns=df.columns[1:])  \n",
    "#y = df.as_matrix(columns=['mpg'])\n",
    "\n",
    "for train, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[train]\n",
    "    y_train_fold = y_train[train]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\nFinal, out of sample score (RMSE): {}\".format(score))    \n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "# Evaluate success using accuracy\n",
    "print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
      "       'acceleration', 'year', 'origin'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x7f869ddb69b0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dc67978>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dfd8c88>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7f869dc75cc0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dcaff98>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dc4ec50>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dc6ab38>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dfe6c50>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dfe6dd8>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7f869dc50588>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dfd8ba8>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dfede48>],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7f869dc507b8>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dc6acc0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dfed630>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x7f869ddb6390>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dc75f60>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dc67ef0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dc4eac8>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dfe7be0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f869dfe7d68>]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAFkCAYAAAAuUDI+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQVj+EuSVDCGvyRJBfOvHKcdz1ONxJIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f869dd73400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "encode_numeric_zscore(df,'mpg')\n",
    "encode_numeric_zscore(df,'acceleration')\n",
    "encode_numeric_zscore(df,'weight')\n",
    "\n",
    "plt.boxplot([df.mpg,df.acceleration,df.weight],labels=['MPG','ACCELERATION','WEGHT'])\n",
    "#plt.boxplot([df.horsepower],labels=['HORSEPOWER'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
