{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the origional column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df,name,target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x)==str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name,tv)\n",
    "        df[name2] = l\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    \n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.int32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "# Regression chart, we will see more of this chart in the next class.\n",
    "def chart_regression(pred,y):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y_test.flatten()})\n",
    "    t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# Get a new directory to hold checkpoints from a neural network.  This allows the neural network to be\n",
    "# loaded later.  If the erase param is set to true, the contents of the directory will be cleared.\n",
    "def get_model_dir(name,erase):\n",
    "    base_path = os.path.join(\".\",\"dnn\")\n",
    "    model_dir = os.path.join(base_path,name)\n",
    "    os.makedirs(model_dir,exist_ok=True)\n",
    "    if erase and len(model_dir)>4 and os.path.isdir(model_dir):\n",
    "        shutil.rmtree(model_dir,ignore_errors=True) # be careful, this deletes everything below the specified path\n",
    "    return model_dir\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name]-df[name].mean())>=(sd*df[name].std()))]\n",
    "    df.drop(drop_rows,axis=0,inplace=True)\n",
    "    \n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low =-1, normalized_high =1, \n",
    "                         data_low=None, data_high=None):\n",
    "    \n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "    \n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "                * (normalized_high - normalized_low) + normalized_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"auto-mpg.csv\",na_values=['NA','?'])\n",
    "#procura por colunas que tenham algum Nan\n",
    "df.isnull().any()\n",
    "#corrige Nan\n",
    "df['horsepower'][df['horsepower'].isnull()] = df.horsepower.mean()\n",
    "df.isnull().any()\n",
    "#remove nome\n",
    "df.drop('name',axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 1 - Linear Regression sem cross-validation\n",
      "Mean squared error: 13.48\n",
      "Mean squared error: 13.481920950078788\n",
      "Mean squared error: [-10.06714444 -14.31106479 -17.2556256 ]\n",
      "Accuracy: 0.775\n",
      "\n",
      "\n",
      "\n",
      "Caso 2 - Linear Regression com 5 fold cross-validation\n",
      "Fold #1\n",
      "Fold score (RMSE): 3.7235565912562794\n",
      "Accuracy: 0.790\n",
      "Fold #2\n",
      "Fold score (RMSE): 2.919909119703647\n",
      "Accuracy: 0.816\n",
      "Fold #3\n",
      "Fold score (RMSE): 3.6712387916603473\n",
      "Accuracy: 0.802\n",
      "Fold #4\n",
      "Fold score (RMSE): 3.2484680021516135\n",
      "Accuracy: 0.826\n",
      "Fold #5\n",
      "Fold score (RMSE): 3.353869925924761\n",
      "Accuracy: 0.820\n",
      "Final, out of sample score (RMSE): 3.396634832260131\n"
     ]
    }
   ],
   "source": [
    "from sklearn                        import metrics, svm\n",
    "from sklearn.linear_model           import LinearRegression\n",
    "from sklearn.linear_model           import LogisticRegression\n",
    "from sklearn.tree                   import DecisionTreeClassifier\n",
    "from sklearn.neighbors              import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis  import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes            import GaussianNB\n",
    "from sklearn.svm                    import SVC\n",
    "from sklearn.svm                    import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Caso 1 - Linear Regression sem cross-validation\n",
    "# Shuffle\n",
    "print(\"Caso 1 - Linear Regression sem cross-validation\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.23, random_state=42) \n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "classifier = LinearRegression()\n",
    "classifier.fit(x_train_scaled, y_train)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % np.mean((classifier.predict(x_test_scaled) - y_test) ** 2))\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "score=cross_val_score(classifier, x_test_scaled, y_test, scoring='neg_mean_squared_error') \n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "#Caso 2 - Linear Regression com 5 fold cross-validation\n",
    "# Shuffle\n",
    "print(\"Caso 2 - Linear Regression com 5 fold cross-validation\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "classifier = LinearRegression()\n",
    "kf = KFold(5)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "x = df.as_matrix(columns=df.columns[1:])  \n",
    "y = df.as_matrix(columns=['mpg'])\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    #Normalization\n",
    "    scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "    x_train_scaled = scaler.transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    \n",
    "    classifier.fit(x_train_scaled, y_train)\n",
    "    pred = classifier.predict(x_test_scaled)\n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
