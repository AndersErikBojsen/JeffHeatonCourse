{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the origional column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df,name,target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x)==str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name,tv)\n",
    "        df[name2] = l\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    \n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.int32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "# Regression chart, we will see more of this chart in the next class.\n",
    "def chart_regression(pred,y):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y})\n",
    "    t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# Get a new directory to hold checkpoints from a neural network.  This allows the neural network to be\n",
    "# loaded later.  If the erase param is set to true, the contents of the directory will be cleared.\n",
    "def get_model_dir(name,erase):\n",
    "    base_path = os.path.join(\".\",\"dnn\")\n",
    "    model_dir = os.path.join(base_path,name)\n",
    "    os.makedirs(model_dir,exist_ok=True)\n",
    "    if erase and len(model_dir)>4 and os.path.isdir(model_dir):\n",
    "        shutil.rmtree(model_dir,ignore_errors=True) # be careful, this deletes everything below the specified path\n",
    "    return model_dir\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name]-df[name].mean())>=(sd*df[name].std()))]\n",
    "    df.drop(drop_rows,axis=0,inplace=True)\n",
    "    \n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low =-1, normalized_high =1, \n",
    "                         data_low=None, data_high=None):\n",
    "    \n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "    \n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "                * (normalized_high - normalized_low) + normalized_low\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esses testes foram feitos com um base sobre carros e seus atributos. O objetivo é prever quantoo carro fará por litro de combustível (ou quantas milhas por galão). Abaixo segue uma porção dessa base.\n",
      "\n",
      "\n",
      "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
      "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
      "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
      "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
      "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
      "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
      "\n",
      "   origin                       name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"auto-mpg.csv\",na_values=['NA','?'])\n",
    "\n",
    "\n",
    "print(\"Esses testes foram feitos com um base sobre carros e seus atributos. O objetivo é prever quanto\"+\n",
    "      \"o carro fará por litro de combustível (ou quantas milhas por galão). Abaixo segue uma porção dessa base.\")        \n",
    "\n",
    "print(\"\\n\")\n",
    "print(df.head())\n",
    "\n",
    "#procura por colunas que tenham algum Nan\n",
    "df.isnull().any()\n",
    "#corrige Nan\n",
    "df['horsepower'][df['horsepower'].isnull()] = df.horsepower.mean()\n",
    "df.isnull().any()\n",
    "#remove nome\n",
    "df.drop('name',axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 1 - Linear Regression sem cross-validation\n",
      "Mean squared error: 13.91\n",
      "Mean squared error: 13.9085822029562\n",
      "Mean squared error: [-17.93147744 -12.4248414  -16.31732339]\n",
      "Accuracy: 0.805\n",
      "\n",
      "\n",
      "\n",
      "Caso 2 - Linear Regression com 5 fold cross-validation\n",
      "Fold #1\n",
      "Fold score (RMSE): 11.431448640762397\n",
      "Accuracy: 0.832\n",
      "Fold #2\n",
      "Fold score (RMSE): 15.303439543598099\n",
      "Accuracy: 0.766\n",
      "Fold #3\n",
      "Fold score (RMSE): 8.249545003203513\n",
      "Accuracy: 0.874\n",
      "Fold #4\n",
      "Fold score (RMSE): 12.753886494402016\n",
      "Accuracy: 0.742\n",
      "Fold #5\n",
      "Fold score (RMSE): 13.110699896511942\n",
      "Accuracy: 0.808\n",
      "Final, out of sample score (RMSE): 12.165008385634202\n",
      "Final Accuracy: 0.839\n",
      "\n",
      "\n",
      "\n",
      " Tentativa de selecionar melhores features \n",
      "\n",
      "Original shape: (398, 7)\n",
      "Shape apos Removing features with low variance (398, 7)\n",
      "\n",
      "\n",
      "As features selecionadas com Tree-based feature selection foram: \n",
      "\n",
      "   cylinders  displacement  horsepower   weight  acceleration      year  \\\n",
      "0   0.361614      0.177944    0.039501  0.23766      0.030649  0.140026   \n",
      "\n",
      "     origin  \n",
      "0  0.012606  \n",
      "\n",
      " New shape apos Tree-based feature selection: (398, 3)\n",
      "\n",
      " Fim tentativa selecionar melhores features \n",
      "\n",
      "Treinando novamente somente com as features relevantes \n",
      "\n",
      "Mean squared error: 0.24\n",
      "Mean squared error: 0.244623965804882\n",
      "Mean squared error: [-0.29399579 -0.32953754 -0.21356833]\n",
      "Accuracy: 0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "from sklearn                        import metrics, svm\n",
    "from sklearn.linear_model           import LinearRegression\n",
    "from sklearn.linear_model           import LogisticRegression\n",
    "from sklearn.tree                   import DecisionTreeClassifier\n",
    "from sklearn.neighbors              import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis  import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes            import GaussianNB\n",
    "from sklearn.svm                    import SVC\n",
    "from sklearn.svm                    import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#Caso 1 - Linear Regression sem cross-validation\n",
    "print(\"Caso 1 - Linear Regression sem cross-validation\")\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "classifier = LinearRegression()\n",
    "classifier.fit(x_train_scaled, y_train)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % np.mean((classifier.predict(x_test_scaled) - y_test) ** 2))\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "score=cross_val_score(classifier, x_test_scaled, y_test, scoring='neg_mean_squared_error') \n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#Caso 2 - Linear Regression com 5 fold cross-validation\n",
    "# Shuffle\n",
    "print(\"Caso 2 - Linear Regression com 5 fold cross-validation\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_train = np.asmatrix(y_train)\n",
    "y_test = np.asmatrix(y_test)\n",
    "\n",
    "classifier = LinearRegression()\n",
    "kf = KFold(5)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "\n",
    "    x_train_fold = x_train_scaled[train]\n",
    "    y_train_fold = y_train[train]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = (metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = (metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\nFinal, out of sample score (RMSE): {}\".format(score))    \n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\n Tentativa de selecionar melhores features \\n\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#Removing features with low variance\n",
    "print(\"Original shape: {}\".format(np.shape(df.iloc[:,1:])))\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "features = sel.fit_transform(df.iloc[:,1:])\n",
    "print(\"Shape apos Removing features with low variance {}\".format(np.shape(features))) #nenhuma foi selecionada \n",
    "print(\"\\n\")\n",
    "#Tree-based feature selection\n",
    "clf = ExtraTreesRegressor()\n",
    "clf = clf.fit(x_train,y_train)\n",
    "data = np.zeros((1,x_train.shape[1]))\n",
    "data = pd.DataFrame(data, columns=df.columns[1:])\n",
    "data.iloc[0] = clf.feature_importances_\n",
    "print(\"As features selecionadas com Tree-based feature selection foram: \\n\")\n",
    "print(data)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(df.iloc[:,1:])\n",
    "print(\"\\n New shape apos Tree-based feature selection: {}\".format(X_new.shape))\n",
    "\n",
    "print(\"\\n Fim tentativa selecionar melhores features \\n\")\n",
    "\n",
    "print(\"Treinando novamente somente com as features relevantes \\n\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_new[:,1:], X_new[:,0:1], test_size=0.23, random_state=42) \n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "classifier = LinearRegression()\n",
    "classifier.fit(x_train_scaled, y_train)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % np.mean((classifier.predict(x_test_scaled) - y_test) ** 2))\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "score=cross_val_score(classifier, x_test_scaled, y_test, scoring='neg_mean_squared_error') \n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 2 - SVM\n",
      "Mean squared error: 12.142503554114109\n",
      "Accuracy: 0.808\n",
      "\n",
      "\n",
      "\n",
      "Caso 2 - SVM com cross-validation\n",
      "Fold #1\n",
      "Fold score (RMSE): 7.456735349681934\n",
      "Accuracy: 0.883\n",
      "Fold #2\n",
      "Fold score (RMSE): 7.0928008375669584\n",
      "Accuracy: 0.835\n",
      "Fold #3\n",
      "Fold score (RMSE): 13.442702986742084\n",
      "Accuracy: 0.775\n",
      "Fold #4\n",
      "Fold score (RMSE): 12.48759888325813\n",
      "Accuracy: 0.806\n",
      "Fold #5\n",
      "Fold score (RMSE): 12.536257043858567\n",
      "Accuracy: 0.801\n",
      "\n",
      "Final, out of sample score (RMSE): 10.591214561458411\n",
      "Final Accuracy: 0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "classifier = SVR()\n",
    "#Caso 3 - SVM\n",
    "# Shuffle\n",
    "print(\"Caso 2 - SVM\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.23, random_state=42) \n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "classifier.fit(x_train_scaled, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#Caso 2\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"Caso 2 - SVM com cross-validation\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_train = np.asmatrix(y_train)\n",
    "y_test = np.asmatrix(y_test)\n",
    "\n",
    "classifier = SVR()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "#x = df.as_matrix(columns=df.columns[1:])  \n",
    "#y = df.as_matrix(columns=['mpg'])\n",
    "\n",
    "\n",
    "for train, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[train]\n",
    "    y_train_fold = y_train[train]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "         \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)\n",
    "\n",
    "    # Measure accuracy\n",
    "    score = (metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = (metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\nFinal, out of sample score (RMSE): {}\".format(score))    \n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "# Evaluate success using accuracy\n",
    "print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests\n",
      "Mean squared error: 4.489934999999998\n",
      "Accuracy: 0.908\n",
      "\n",
      "\n",
      "\n",
      "Random Forests com cross-validation\n",
      "Fold #1\n",
      "Fold score (RMSE): 4.485018749999997\n",
      "Accuracy: 0.924\n",
      "Fold #2\n",
      "Fold score (RMSE): 6.891831249999997\n",
      "Accuracy: 0.889\n",
      "Fold #3\n",
      "Fold score (RMSE): 13.660921874999998\n",
      "Accuracy: 0.783\n",
      "Fold #4\n",
      "Fold score (RMSE): 11.132809523809525\n",
      "Accuracy: 0.830\n",
      "Fold #5\n",
      "Fold score (RMSE): 7.858160317460318\n",
      "Accuracy: 0.869\n",
      "\n",
      "Final, out of sample score (RMSE): 8.80141037735849\n",
      "Final Accuracy: 0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/home/christian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "##Random Forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"Random Forests\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test,y=y_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#Caso 2\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"Random Forests com cross-validation\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "#x = df.as_matrix(columns=df.columns[1:])  \n",
    "#y = df.as_matrix(columns=['mpg'])\n",
    "\n",
    "for train, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train.as_matrix()[train]\n",
    "    y_train_fold = y_train.as_matrix()[train]\n",
    "    x_test_fold = x_train.as_matrix()[test]\n",
    "    y_test_fold = y_train.as_matrix()[test]\n",
    "    \n",
    "    #Normalization\n",
    "    #scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "    #x_train_scaled = scaler.transform(x_train)\n",
    "    #x_test_scaled = scaler.transform(x_test)\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = (metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = (metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\nFinal, out of sample score (RMSE): {}\".format(score))    \n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "# Evaluate success using accuracy\n",
    "print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test,y=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n",
      "Mean squared error: 6.889565000000002\n",
      "Accuracy: 0.900\n",
      "\n",
      "\n",
      "KNeighborsRegressor com cross-validation\n",
      "Fold #1\n",
      "Fold score (RMSE): 10.699481249999996\n",
      "Accuracy: 0.792\n",
      "Fold #2\n",
      "Fold score (RMSE): 6.526981249999997\n",
      "Accuracy: 0.895\n",
      "Fold #3\n",
      "Fold score (RMSE): 6.904775000000001\n",
      "Accuracy: 0.890\n",
      "Fold #4\n",
      "Fold score (RMSE): 14.485784126984132\n",
      "Accuracy: 0.784\n",
      "Fold #5\n",
      "Fold score (RMSE): 9.675079365079364\n",
      "Accuracy: 0.859\n",
      "\n",
      "Final, out of sample score (RMSE): 9.643187421383649\n",
      "Final, out of sample score (RMSE): 7.205770000000001\n",
      "Final Accuracy: 0.868\n"
     ]
    }
   ],
   "source": [
    "##K NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"KNeighborsRegressor\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "classifier = KNeighborsRegressor()\n",
    "\n",
    "classifier.fit(x_train_scaled, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#Caso 2\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"KNeighborsRegressor com cross-validation\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_train = np.asmatrix(y_train)\n",
    "y_test = np.asmatrix(y_test)\n",
    "\n",
    "\n",
    "classifier = KNeighborsRegressor()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "#x = df.as_matrix(columns=df.columns[1:])  \n",
    "#y = df.as_matrix(columns=['mpg'])\n",
    "\n",
    "for train, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[train]\n",
    "    y_train_fold = y_train[train]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "     \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = (metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = (metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\nFinal, out of sample score (RMSE): {}\".format(score))    \n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "# Evaluate success using accuracy\n",
    "print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN MLPRegressor\n",
      "Mean squared error: 6.062708435480688\n",
      "Accuracy: 0.888\n",
      "\n",
      "\n",
      "MLPRegressor com cross-validation\n",
      "Fold #1\n",
      "Fold score (RMSE): 15.601447110421054\n",
      "Accuracy: 0.726\n",
      "Fold #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (RMSE): 16.605812043036607\n",
      "Accuracy: 0.739\n",
      "Fold #3\n",
      "Fold score (RMSE): 6.560272046905166\n",
      "Accuracy: 0.910\n",
      "Fold #4\n",
      "Fold score (RMSE): 7.466332912675582\n",
      "Accuracy: 0.879\n",
      "Fold #5\n",
      "Fold score (RMSE): 8.40559289908556\n",
      "Accuracy: 0.847\n",
      "\n",
      "Final, out of sample score (RMSE): 10.946708562780417\n",
      "Final, out of sample score (RMSE): 6.498341300325178\n",
      "Final Accuracy: 0.880\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"NN MLPRegressor\")\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.23, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15, 2), random_state=1)\n",
    "\n",
    "classifier.fit(x_train_scaled, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#Caso 2\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"MLPRegressor com cross-validation\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0:1], test_size=0.20, random_state=42) \n",
    "\n",
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_train = np.asmatrix(y_train)\n",
    "y_test = np.asmatrix(y_test)\n",
    "\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15, 2), random_state=1)\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "#x = df.as_matrix(columns=df.columns[1:])  \n",
    "#y = df.as_matrix(columns=['mpg'])\n",
    "\n",
    "for train, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[train]\n",
    "    y_train_fold = y_train[train]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = (metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = (metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\nFinal, out of sample score (RMSE): {}\".format(score))    \n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test_scaled)\n",
    "score = metrics.mean_squared_error(y_test, pred)\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "# Evaluate success using accuracy\n",
    "print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "encode_numeric_zscore(df,'mpg')\n",
    "encode_numeric_zscore(df,'acceleration')\n",
    "encode_numeric_zscore(df,'weight')\n",
    "\n",
    "plt.boxplot([df.mpg,df.acceleration,df.weight],labels=['MPG','ACCELERATION','WEGHT'])\n",
    "#plt.boxplot([df.horsepower],labels=['HORSEPOWER'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
